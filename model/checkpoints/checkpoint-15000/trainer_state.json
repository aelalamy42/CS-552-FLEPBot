{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4499758337361044,
  "eval_steps": 500,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04833252779120348,
      "grad_norm": 1.510177493095398,
      "learning_rate": 1.9677783148058642e-07,
      "logits/chosen": 0.00035744759952649474,
      "logits/rejected": 0.00037470899405889213,
      "logps/chosen": -3248.2587890625,
      "logps/rejected": -2560.581787109375,
      "loss": 0.693,
      "rewards/accuracies": 0.6150000095367432,
      "rewards/chosen": 0.001390756224282086,
      "rewards/margins": 0.0002838659274857491,
      "rewards/rejected": 0.0011068902676925063,
      "step": 500
    },
    {
      "epoch": 0.09666505558240696,
      "grad_norm": 1.2730121612548828,
      "learning_rate": 1.9355566296117284e-07,
      "logits/chosen": 0.0003811155038420111,
      "logits/rejected": 0.0003348864265717566,
      "logps/chosen": -3286.341064453125,
      "logps/rejected": -2499.927001953125,
      "loss": 0.6927,
      "rewards/accuracies": 0.6629999876022339,
      "rewards/chosen": 0.004462511278688908,
      "rewards/margins": 0.000980821205303073,
      "rewards/rejected": 0.003481689840555191,
      "step": 1000
    },
    {
      "epoch": 0.14499758337361043,
      "grad_norm": 1.6152931451797485,
      "learning_rate": 1.903334944417593e-07,
      "logits/chosen": 0.00028154789470136166,
      "logits/rejected": 0.0002628993825055659,
      "logps/chosen": -3146.686279296875,
      "logps/rejected": -2505.78857421875,
      "loss": 0.6923,
      "rewards/accuracies": 0.628000020980835,
      "rewards/chosen": 0.007902194745838642,
      "rewards/margins": 0.0016465454827994108,
      "rewards/rejected": 0.006255649495869875,
      "step": 1500
    },
    {
      "epoch": 0.1933301111648139,
      "grad_norm": 0.9524547457695007,
      "learning_rate": 1.8711132592234572e-07,
      "logits/chosen": 0.0004913898301310837,
      "logits/rejected": 0.0004315704572945833,
      "logps/chosen": -3342.46923828125,
      "logps/rejected": -2601.353271484375,
      "loss": 0.6918,
      "rewards/accuracies": 0.6710000038146973,
      "rewards/chosen": 0.012398791499435902,
      "rewards/margins": 0.002711669774726033,
      "rewards/rejected": 0.009687121957540512,
      "step": 2000
    },
    {
      "epoch": 0.2416626389560174,
      "grad_norm": 1.6385157108306885,
      "learning_rate": 1.8388915740293217e-07,
      "logits/chosen": 0.0004913907614536583,
      "logits/rejected": 0.0003119884058833122,
      "logps/chosen": -3379.216064453125,
      "logps/rejected": -2613.8974609375,
      "loss": 0.6914,
      "rewards/accuracies": 0.6230000257492065,
      "rewards/chosen": 0.01720343716442585,
      "rewards/margins": 0.0035093207843601704,
      "rewards/rejected": 0.013694114983081818,
      "step": 2500
    },
    {
      "epoch": 0.28999516674722087,
      "grad_norm": 0.9608391523361206,
      "learning_rate": 1.806669888835186e-07,
      "logits/chosen": 0.00039036726229824126,
      "logits/rejected": 0.00026111872284673154,
      "logps/chosen": -3183.21337890625,
      "logps/rejected": -2540.60986328125,
      "loss": 0.6913,
      "rewards/accuracies": 0.6290000081062317,
      "rewards/chosen": 0.019908180460333824,
      "rewards/margins": 0.003699540626257658,
      "rewards/rejected": 0.01620863936841488,
      "step": 3000
    },
    {
      "epoch": 0.3383276945384244,
      "grad_norm": 2.1310415267944336,
      "learning_rate": 1.7744482036410505e-07,
      "logits/chosen": 0.0004673754738178104,
      "logits/rejected": 0.0004203810531180352,
      "logps/chosen": -3126.594482421875,
      "logps/rejected": -2489.041015625,
      "loss": 0.6907,
      "rewards/accuracies": 0.6549999713897705,
      "rewards/chosen": 0.02432912215590477,
      "rewards/margins": 0.005020193289965391,
      "rewards/rejected": 0.01930893398821354,
      "step": 3500
    },
    {
      "epoch": 0.3866602223296278,
      "grad_norm": 1.2593270540237427,
      "learning_rate": 1.7422265184469147e-07,
      "logits/chosen": 0.00042180807213298976,
      "logits/rejected": 0.00031298468820750713,
      "logps/chosen": -3305.74658203125,
      "logps/rejected": -2484.75537109375,
      "loss": 0.6897,
      "rewards/accuracies": 0.6589999794960022,
      "rewards/chosen": 0.029426224529743195,
      "rewards/margins": 0.006987685337662697,
      "rewards/rejected": 0.022438539192080498,
      "step": 4000
    },
    {
      "epoch": 0.43499275012083133,
      "grad_norm": 1.4543739557266235,
      "learning_rate": 1.710004833252779e-07,
      "logits/chosen": 0.00040144717786461115,
      "logits/rejected": 0.0003776536323130131,
      "logps/chosen": -3064.081787109375,
      "logps/rejected": -2523.985107421875,
      "loss": 0.6906,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.032763153314590454,
      "rewards/margins": 0.005156423896551132,
      "rewards/rejected": 0.027606727555394173,
      "step": 4500
    },
    {
      "epoch": 0.4833252779120348,
      "grad_norm": 1.1724891662597656,
      "learning_rate": 1.6777831480586432e-07,
      "logits/chosen": 0.00027737129130400717,
      "logits/rejected": 0.00022838848235551268,
      "logps/chosen": -3386.857421875,
      "logps/rejected": -2500.998046875,
      "loss": 0.6883,
      "rewards/accuracies": 0.6620000004768372,
      "rewards/chosen": 0.04086408019065857,
      "rewards/margins": 0.009932074695825577,
      "rewards/rejected": 0.030931999906897545,
      "step": 5000
    },
    {
      "epoch": 0.5316578057032383,
      "grad_norm": 0.9193143248558044,
      "learning_rate": 1.6455614628645077e-07,
      "logits/chosen": 0.0003231884620618075,
      "logits/rejected": 0.00027109196525998414,
      "logps/chosen": -3180.319091796875,
      "logps/rejected": -2588.056884765625,
      "loss": 0.6889,
      "rewards/accuracies": 0.6549999713897705,
      "rewards/chosen": 0.044250186532735825,
      "rewards/margins": 0.008732639253139496,
      "rewards/rejected": 0.03551754727959633,
      "step": 5500
    },
    {
      "epoch": 0.5799903334944417,
      "grad_norm": 0.941222071647644,
      "learning_rate": 1.613339777670372e-07,
      "logits/chosen": 0.0003952758270315826,
      "logits/rejected": 0.0003701050591189414,
      "logps/chosen": -3352.940673828125,
      "logps/rejected": -2557.75634765625,
      "loss": 0.6874,
      "rewards/accuracies": 0.6269999742507935,
      "rewards/chosen": 0.05306030437350273,
      "rewards/margins": 0.011833406053483486,
      "rewards/rejected": 0.04122689366340637,
      "step": 6000
    },
    {
      "epoch": 0.6283228612856452,
      "grad_norm": 0.8541644811630249,
      "learning_rate": 1.5811180924762365e-07,
      "logits/chosen": 0.0003855759568978101,
      "logits/rejected": 0.00028912408743053675,
      "logps/chosen": -3288.01611328125,
      "logps/rejected": -2488.78515625,
      "loss": 0.6868,
      "rewards/accuracies": 0.6510000228881836,
      "rewards/chosen": 0.05667661502957344,
      "rewards/margins": 0.013122583739459515,
      "rewards/rejected": 0.04355403035879135,
      "step": 6500
    },
    {
      "epoch": 0.6766553890768487,
      "grad_norm": 1.315942645072937,
      "learning_rate": 1.5488964072821008e-07,
      "logits/chosen": 0.0003488007641863078,
      "logits/rejected": 0.00037700653774663806,
      "logps/chosen": -3147.474853515625,
      "logps/rejected": -2461.638427734375,
      "loss": 0.6871,
      "rewards/accuracies": 0.6610000133514404,
      "rewards/chosen": 0.06141810491681099,
      "rewards/margins": 0.01250297948718071,
      "rewards/rejected": 0.04891512542963028,
      "step": 7000
    },
    {
      "epoch": 0.7249879168680522,
      "grad_norm": 0.9190616607666016,
      "learning_rate": 1.5166747220879653e-07,
      "logits/chosen": 0.0005535015370696783,
      "logits/rejected": 0.0005582314915955067,
      "logps/chosen": -3206.09716796875,
      "logps/rejected": -2485.9931640625,
      "loss": 0.6863,
      "rewards/accuracies": 0.656000018119812,
      "rewards/chosen": 0.06859704107046127,
      "rewards/margins": 0.014310440048575401,
      "rewards/rejected": 0.05428659915924072,
      "step": 7500
    },
    {
      "epoch": 0.7733204446592556,
      "grad_norm": 1.9810911417007446,
      "learning_rate": 1.4844530368938295e-07,
      "logits/chosen": 0.0004205480800010264,
      "logits/rejected": 0.0003809237095993012,
      "logps/chosen": -3314.68505859375,
      "logps/rejected": -2715.865966796875,
      "loss": 0.6867,
      "rewards/accuracies": 0.6029999852180481,
      "rewards/chosen": 0.07533545792102814,
      "rewards/margins": 0.013409415259957314,
      "rewards/rejected": 0.061926040798425674,
      "step": 8000
    },
    {
      "epoch": 0.8216529724504592,
      "grad_norm": 1.7596657276153564,
      "learning_rate": 1.4522313516996938e-07,
      "logits/chosen": 0.0003823929000645876,
      "logits/rejected": 0.000459925300674513,
      "logps/chosen": -3266.988037109375,
      "logps/rejected": -2565.957275390625,
      "loss": 0.6856,
      "rewards/accuracies": 0.6439999938011169,
      "rewards/chosen": 0.08039546757936478,
      "rewards/margins": 0.01577894203364849,
      "rewards/rejected": 0.06461653113365173,
      "step": 8500
    },
    {
      "epoch": 0.8699855002416627,
      "grad_norm": 2.353039264678955,
      "learning_rate": 1.420009666505558e-07,
      "logits/chosen": 0.00045366500853560865,
      "logits/rejected": 0.00044974786578677595,
      "logps/chosen": -3256.60009765625,
      "logps/rejected": -2516.237060546875,
      "loss": 0.6841,
      "rewards/accuracies": 0.6470000147819519,
      "rewards/chosen": 0.0880088284611702,
      "rewards/margins": 0.018938325345516205,
      "rewards/rejected": 0.06907051056623459,
      "step": 9000
    },
    {
      "epoch": 0.9183180280328661,
      "grad_norm": 1.7239000797271729,
      "learning_rate": 1.3877879813114226e-07,
      "logits/chosen": 0.0004548292781691998,
      "logits/rejected": 0.00039800142985768616,
      "logps/chosen": -3080.642822265625,
      "logps/rejected": -2491.9599609375,
      "loss": 0.6854,
      "rewards/accuracies": 0.609000027179718,
      "rewards/chosen": 0.08966730535030365,
      "rewards/margins": 0.01627468131482601,
      "rewards/rejected": 0.07339262217283249,
      "step": 9500
    },
    {
      "epoch": 0.9666505558240696,
      "grad_norm": 1.4973798990249634,
      "learning_rate": 1.3555662961172868e-07,
      "logits/chosen": 0.000443193013779819,
      "logits/rejected": 0.0003681511734612286,
      "logps/chosen": -3247.715087890625,
      "logps/rejected": -2470.136474609375,
      "loss": 0.6824,
      "rewards/accuracies": 0.6589999794960022,
      "rewards/chosen": 0.09957858920097351,
      "rewards/margins": 0.022628551349043846,
      "rewards/rejected": 0.07695002853870392,
      "step": 10000
    },
    {
      "epoch": 1.0149830836152731,
      "grad_norm": 2.4872894287109375,
      "learning_rate": 1.323344610923151e-07,
      "logits/chosen": 0.0004169520689174533,
      "logits/rejected": 0.00033590421662665904,
      "logps/chosen": -3126.637939453125,
      "logps/rejected": -2453.0439453125,
      "loss": 0.6835,
      "rewards/accuracies": 0.6299999952316284,
      "rewards/chosen": 0.10114690661430359,
      "rewards/margins": 0.020416509360074997,
      "rewards/rejected": 0.0807303935289383,
      "step": 10500
    },
    {
      "epoch": 1.0633156114064766,
      "grad_norm": 1.752289056777954,
      "learning_rate": 1.2911229257290156e-07,
      "logits/chosen": 0.0003422305453568697,
      "logits/rejected": 0.00038287771167233586,
      "logps/chosen": -3365.141357421875,
      "logps/rejected": -2542.639892578125,
      "loss": 0.6805,
      "rewards/accuracies": 0.6589999794960022,
      "rewards/chosen": 0.11395503580570221,
      "rewards/margins": 0.02667553722858429,
      "rewards/rejected": 0.08727949857711792,
      "step": 11000
    },
    {
      "epoch": 1.11164813919768,
      "grad_norm": 1.1033577919006348,
      "learning_rate": 1.25890124053488e-07,
      "logits/chosen": 0.0003991237317677587,
      "logits/rejected": 0.0003670386504381895,
      "logps/chosen": -3222.560546875,
      "logps/rejected": -2584.362060546875,
      "loss": 0.6821,
      "rewards/accuracies": 0.6349999904632568,
      "rewards/chosen": 0.11898576468229294,
      "rewards/margins": 0.023610318079590797,
      "rewards/rejected": 0.09537544846534729,
      "step": 11500
    },
    {
      "epoch": 1.1599806669888835,
      "grad_norm": 1.2515130043029785,
      "learning_rate": 1.2266795553407444e-07,
      "logits/chosen": 0.00033234176225960255,
      "logits/rejected": 0.0002760344941634685,
      "logps/chosen": -3253.440673828125,
      "logps/rejected": -2614.979736328125,
      "loss": 0.6819,
      "rewards/accuracies": 0.6480000019073486,
      "rewards/chosen": 0.12346849590539932,
      "rewards/margins": 0.02399258315563202,
      "rewards/rejected": 0.0994759276509285,
      "step": 12000
    },
    {
      "epoch": 1.208313194780087,
      "grad_norm": 1.6201332807540894,
      "learning_rate": 1.1944578701466086e-07,
      "logits/chosen": 0.0004906390677206218,
      "logits/rejected": 0.0004352917312644422,
      "logps/chosen": -3218.4306640625,
      "logps/rejected": -2523.794921875,
      "loss": 0.6802,
      "rewards/accuracies": 0.6439999938011169,
      "rewards/chosen": 0.1305297315120697,
      "rewards/margins": 0.027792755514383316,
      "rewards/rejected": 0.10273696482181549,
      "step": 12500
    },
    {
      "epoch": 1.2566457225712906,
      "grad_norm": 0.7591686248779297,
      "learning_rate": 1.1622361849524729e-07,
      "logits/chosen": 0.0004041599459014833,
      "logits/rejected": 0.00045945667079649866,
      "logps/chosen": -3350.903564453125,
      "logps/rejected": -2627.423583984375,
      "loss": 0.6796,
      "rewards/accuracies": 0.6489999890327454,
      "rewards/chosen": 0.14117509126663208,
      "rewards/margins": 0.029024654999375343,
      "rewards/rejected": 0.11215043812990189,
      "step": 13000
    },
    {
      "epoch": 1.304978250362494,
      "grad_norm": 1.5399634838104248,
      "learning_rate": 1.1300144997583374e-07,
      "logits/chosen": 0.0004080862272530794,
      "logits/rejected": 0.0003940708702430129,
      "logps/chosen": -3213.408203125,
      "logps/rejected": -2544.914306640625,
      "loss": 0.68,
      "rewards/accuracies": 0.640999972820282,
      "rewards/chosen": 0.1409667581319809,
      "rewards/margins": 0.02821844071149826,
      "rewards/rejected": 0.11274831742048264,
      "step": 13500
    },
    {
      "epoch": 1.3533107781536975,
      "grad_norm": 1.6042287349700928,
      "learning_rate": 1.0977928145642016e-07,
      "logits/chosen": 0.0005617688875645399,
      "logits/rejected": 0.0005629390361718833,
      "logps/chosen": -3192.971923828125,
      "logps/rejected": -2591.870849609375,
      "loss": 0.6811,
      "rewards/accuracies": 0.6200000047683716,
      "rewards/chosen": 0.14724108576774597,
      "rewards/margins": 0.026700759306550026,
      "rewards/rejected": 0.12054034322500229,
      "step": 14000
    },
    {
      "epoch": 1.401643305944901,
      "grad_norm": 1.754150152206421,
      "learning_rate": 1.065571129370066e-07,
      "logits/chosen": 0.0003925271739717573,
      "logits/rejected": 0.0003712819889187813,
      "logps/chosen": -3158.393798828125,
      "logps/rejected": -2508.713134765625,
      "loss": 0.6781,
      "rewards/accuracies": 0.6549999713897705,
      "rewards/chosen": 0.15338744223117828,
      "rewards/margins": 0.03272617980837822,
      "rewards/rejected": 0.12066126614809036,
      "step": 14500
    },
    {
      "epoch": 1.4499758337361044,
      "grad_norm": 1.5267689228057861,
      "learning_rate": 1.0333494441759303e-07,
      "logits/chosen": 0.00019547042029444128,
      "logits/rejected": 0.00015627944958396256,
      "logps/chosen": -3438.957763671875,
      "logps/rejected": -2667.037353515625,
      "loss": 0.6775,
      "rewards/accuracies": 0.6349999904632568,
      "rewards/chosen": 0.16761688888072968,
      "rewards/margins": 0.03407294303178787,
      "rewards/rejected": 0.13354390859603882,
      "step": 15000
    }
  ],
  "logging_steps": 500,
  "max_steps": 31035,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
